Public Linkage Disequilibrium Datasets
======================================

.. comment: begin: goto-read-the-docs

.. container:: visible-only-on-github

   +-----------------------------------------------------------------------------------+
   | **The properly rendered version of this document can be found at Read The Docs.** |
   |                                                                                   |
   | **If you are reading this on github, you should instead click** `here`__.         |
   +-----------------------------------------------------------------------------------+

.. _RenderedVersion: http://googlegenomics.readthedocs.org/en/latest/use_cases/linkage_disequilibrium/public_ld_datasets.html

__ RenderedVersion_

.. comment: end: goto-read-the-docs

.. toctree::
   :maxdepth: 2

.. contents::

These pipelines take linkage disequilibrium (LD) results generated by the :doc:`/use_cases/linkage_disequilibrium/compute_linkage_disequilibrium` pipeline and transform them into `Cloud BigQuery <https://cloud.google.com/bigquery/>`_ and `Cloud BigTable <https://cloud.google.com/bigtable/docs/>`_ datasets that can be efficiently analyzed. Each pipeline takes as input:

* a set of LD results

and exports, transforms, and loads the results into the appropriate target data store.

The pipelines are implemented on `Google Cloud Dataflow`_.

Setup Dataflow
--------------

.. include:: /includes/collapsible_dataflow_setup_instructions.rst

Load Linkage Disequilibrium Data into Cloud BigQuery
----------------------------------------------------

The output of the LinkageDisequilibrium pipeline is a file of comma-separated values. This is a standard file format for BigQuery ingestion. General instructions for loading data into BigQuery are available
`here <https://cloud.google.com/bigquery/loading-data-into-bigquery>`_. An example script for loading data from a CSV is available at `load_data_from_csv.py <https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/bigquery/api/load_data_from_csv.py>`_.

When using that script, the `schema <https://cloud.google.com/bigquery/docs/reference/v2/tables>`_ for the table of LD results is available in the `linkage disequilibrium repository <https://github.com/googlegenomics/linkage-disequilibrium>`_ in the `ld_bigquery_schema_fields.txt <https://github.com/googlegenomics/linkage-disequilibrium/blob/master/schema/ld_bigquery_schema_fields.txt>`_ file.

Consequently, LD data can be loaded into a BigQuery table with the following code snippet:

.. code-block:: shell

  PROJECTID=<your-project-id>
  DATASETID=<your-bigquery-dataset-id>
  TABLE=<your-desired-bigquery-table-name>
  DATA=<path-to-linkage-disequilibrium-result-data>

  python path/to/load_data_from_csv.py \
    $PROJECTID $DATASETID $TABLE schema/ld_bigquery_schema_fields.txt $DATA

Load Linkage Disequilibrium Data into Cloud BigTable
----------------------------------------------------

Because BigTable allows efficient access to extremely large datasets indexed by a single key, it is a natural choice for representation of LD data. The `WriteLdBigtable <https://github.com/googlegenomics/linkage-disequilibrium/blob/master/src/main/java/com/google/cloud/genomics/dataflow/pipelines/WriteLdBigtable.java>`_ pipeline converts data generated by the :doc:`/use_cases/linkage_disequilibrium/compute_linkage_disequilibrium` pipeline and writes the results into a BigTable using Dataflow. The key for each BigTable row is designed so that all LD results for a single query variant appear in a contiguous block of the table, sorted by the location of the target variants, and results for query variants are sorted by the location of query variants. This key design allows efficient access to all LD results for a single variant or a single region of the genome.

The following command will load LD results into an existing BigTable:

.. code-block:: shell

  java -Xbootclasspath/p:PATH/TO/YOUR/alpn-boot-YOUR-ALPN-JAR-VERSION.jar \
    -cp /PATH/TO/linkage-disequilibrium*runnable.jar \
    com.google.cloud.genomics.dataflow.pipelines.WriteLdBigtable \
    --bigtableProjectId=YOUR_BIGTABLE_PROJECT_ID \
    --bigtableClusterId=YOUR_BIGTABLE_CLUSTER_ID \
    --bigtableZoneId=YOUR_BIGTABLE_ZONE_ID \
    --bigtableTableId=YOUR_BIGTABLE_TABLE_ID \
    --ldInput="gs://YOUR-BUCKET/PATH-TO-DIRECTORY-WITH-LD-RESULTS/\*"

.. include:: /includes/dataflow_on_gce_run.rst

Retrieve Linkage Disequilibrium Data from Cloud BigTable
----------------------------------------------------

Once a BigTable storing LD data has been created, a mechanism for accessing the results must be created. The `QueryLdBigtable <https://github.com/googlegenomics/linkage-disequilibrium/blob/master/src/main/java/com/google/cloud/genomics/dataflow/pipelines/QueryLdBigtable.java>`_ pipeline provides an example in which Dataflow is used to read a subset of data from an LD BigTable and write the results to GCS in the same format as it was originally written by the :doc:`/use_cases/linkage_disequilibrium/compute_linkage_disequilibrium` pipeline.

The following command will query LD results for a specific region of the genome and write results to a Cloud bucket:

.. code-block:: shell

  java -Xbootclasspath/p:PATH/TO/YOUR/alpn-boot-YOUR-ALPN-JAR-VERSION.jar \
    -cp /PATH/TO/linkage-disequilibrium*runnable.jar \
    com.google.cloud.genomics.dataflow.pipelines.QueryLdBigtable \
    --bigtableProjectId=YOUR_BIGTABLE_PROJECT_ID \
    --bigtableClusterId=YOUR_BIGTABLE_CLUSTER_ID \
    --bigtableZoneId=YOUR_BIGTABLE_ZONE_ID \
    --bigtableTableId=YOUR_BIGTABLE_TABLE_ID \
    --queryRange="17:41196311-41277499"
    --resultLocation="gs://YOUR-BUCKET/PATH-TO-OUTPUT-FILE"

|dataflowSomeRefs|

|dataflowAllRefs|

Additional details
------------------

.. include:: ../../includes/dataflow_details.rst
